{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar100_resnet56.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "10M7fRuEoBmgrAXsFvdylyPRAFjewSvda",
      "authorship_tag": "ABX9TyM+1jn1XMcTdpxhYn3iUrAo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tor4z/colab/blob/main/cifar100_resnet56.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kd0C-AN9i9E"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5i0fuqx87Dm"
      },
      "source": [
        "'''\n",
        "Properly implemented ResNet-s for CIFAR10 as described in paper [1].\n",
        "The implementation and structure of this file is hugely influenced by [2]\n",
        "which is implemented for ImageNet and doesn't have option A for identity.\n",
        "Moreover, most of the implementations on the web is copy-paste from\n",
        "torchvision's resnet and has wrong number of params.\n",
        "Proper ResNet-s for CIFAR10 (for fair comparision and etc.) has following\n",
        "number of layers and parameters:\n",
        "name      | layers | params\n",
        "ResNet20  |    20  | 0.27M\n",
        "ResNet32  |    32  | 0.46M\n",
        "ResNet44  |    44  | 0.66M\n",
        "ResNet56  |    56  | 0.85M\n",
        "ResNet110 |   110  |  1.7M\n",
        "ResNet1202|  1202  | 19.4m\n",
        "which this implementation indeed has.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "[2] https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
        "If you use this implementation in you work, please don't forget to mention the\n",
        "author, Yerlan Idelbayev.\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "__all__ = ['ResNet', 'resnet20', 'resnet32', 'resnet44', 'resnet56', 'resnet110', 'resnet1202']\n",
        "\n",
        "def _weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    #print(classname)\n",
        "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "        init.kaiming_normal_(m.weight)\n",
        "\n",
        "class LambdaLayer(nn.Module):\n",
        "    def __init__(self, lambd):\n",
        "        super(LambdaLayer, self).__init__()\n",
        "        self.lambd = lambd\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lambd(x)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            if option == 'A':\n",
        "                \"\"\"\n",
        "                For CIFAR10 ResNet paper uses option A.\n",
        "                \"\"\"\n",
        "                self.shortcut = LambdaLayer(lambda x:\n",
        "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
        "            elif option == 'B':\n",
        "                self.shortcut = nn.Sequential(\n",
        "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                     nn.BatchNorm2d(self.expansion * planes)\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=100):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 16\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "        self.linear = nn.Linear(64, num_classes)\n",
        "\n",
        "        self.apply(_weights_init)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.avg_pool2d(out, out.size()[3])\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def resnet20():\n",
        "    return ResNet(BasicBlock, [3, 3, 3])\n",
        "\n",
        "\n",
        "def resnet32():\n",
        "    return ResNet(BasicBlock, [5, 5, 5])\n",
        "\n",
        "\n",
        "def resnet44():\n",
        "    return ResNet(BasicBlock, [7, 7, 7])\n",
        "\n",
        "\n",
        "def resnet56():\n",
        "    return ResNet(BasicBlock, [9, 9, 9])\n",
        "\n",
        "\n",
        "def resnet110():\n",
        "    return ResNet(BasicBlock, [18, 18, 18])\n",
        "\n",
        "\n",
        "def resnet1202():\n",
        "    return ResNet(BasicBlock, [200, 200, 200])\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6vzHLyw-4mq",
        "outputId": "330b2956-552f-484c-e5f9-a88617a548ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "\n",
        "best_prec1 = 0\n",
        "save_dir = './data'\n",
        "\n",
        "def main():\n",
        "    global best_prec1\n",
        "    model = torch.nn.DataParallel(resnet56())\n",
        "    model.cuda()\n",
        "\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.CIFAR100(root='./data', train=True, transform=transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomCrop(32, 4),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]), download=True),\n",
        "        batch_size=256, shuffle=True,\n",
        "        num_workers=10, pin_memory=True)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])),\n",
        "        batch_size=128, shuffle=False,\n",
        "        num_workers=10, pin_memory=True)\n",
        "\n",
        "    # define loss function (criterion) and optimizer\n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(), 0.1,\n",
        "                                momentum=0.9,\n",
        "                                weight_decay=1.0e-4)\n",
        "\n",
        "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, \n",
        "             milestones=[100, 150], last_epoch=0 - 1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if False:\n",
        "        validate(val_loader, model, criterion)\n",
        "        return\n",
        "\n",
        "    for epoch in range(0, 500):\n",
        "\n",
        "        # train for one epoch\n",
        "        print('current lr {:.5e}'.format(optimizer.param_groups[0]['lr']))\n",
        "        train(train_loader, model, criterion, optimizer, epoch)\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        # evaluate on validation set\n",
        "        prec1 = validate(val_loader, model, criterion)\n",
        "\n",
        "        # remember best prec@1 and save checkpoint\n",
        "        is_best = prec1 > best_prec1\n",
        "        best_prec1 = max(prec1, best_prec1)\n",
        "\n",
        "        if epoch > 0 and epoch % 100 == 0:\n",
        "            save_checkpoint({\n",
        "                'epoch': epoch + 1,\n",
        "                'state_dict': model.state_dict(),\n",
        "                'best_prec1': best_prec1,\n",
        "            }, is_best, filename=os.path.join(save_dir, 'checkpoint.th'))\n",
        "\n",
        "        save_checkpoint({\n",
        "            'state_dict': model.state_dict(),\n",
        "            'best_prec1': best_prec1,\n",
        "        }, is_best, filename=os.path.join(save_dir, 'model.th'))\n",
        "\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    \"\"\"\n",
        "        Run one train epoch\n",
        "    \"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        target = target.cuda()\n",
        "        input_var = input.cuda()\n",
        "        target_var = target\n",
        "\n",
        "        # compute output\n",
        "        output = model(input_var)\n",
        "        loss = criterion(output, target_var)\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        output = output.float()\n",
        "        loss = loss.float()\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target)[0]\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(prec1.item(), input.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                      data_time=data_time, loss=losses, top1=top1))\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion):\n",
        "    \"\"\"\n",
        "    Run evaluation\n",
        "    \"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, (input, target) in enumerate(val_loader):\n",
        "            target = target.cuda()\n",
        "            input_var = input.cuda()\n",
        "            target_var = target.cuda()\n",
        "\n",
        "            # compute output\n",
        "            output = model(input_var)\n",
        "            loss = criterion(output, target_var)\n",
        "\n",
        "            output = output.float()\n",
        "            loss = loss.float()\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            prec1 = accuracy(output.data, target)[0]\n",
        "            losses.update(loss.item(), input.size(0))\n",
        "            top1.update(prec1.item(), input.size(0))\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print('Test: [{0}/{1}]\\t'\n",
        "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                          i, len(val_loader), batch_time=batch_time, loss=losses,\n",
        "                          top1=top1))\n",
        "\n",
        "    print(' * Prec@1 {top1.avg:.3f}'\n",
        "          .format(top1=top1))\n",
        "\n",
        "    return top1.avg\n",
        "\n",
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    \"\"\"\n",
        "    Save the training model\n",
        "    \"\"\"\n",
        "    torch.save(state, filename)\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "current lr 1.00000e-01\n",
            "Epoch: [0][0/196]\tTime 1.208 (1.208)\tData 0.883 (0.883)\tLoss 9.5308 (9.5308)\tPrec@1 0.391 (0.391)\n",
            "Epoch: [0][100/196]\tTime 0.134 (0.149)\tData 0.000 (0.009)\tLoss 4.5766 (4.8678)\tPrec@1 1.172 (1.280)\n",
            "Test: [0/79]\tTime 0.524 (0.524)\tLoss 4.7075 (4.7075)\tPrec@1 0.000 (0.000)\n",
            " * Prec@1 0.200\n",
            "current lr 1.00000e-01\n",
            "Epoch: [1][0/196]\tTime 1.331 (1.331)\tData 0.977 (0.977)\tLoss 4.5228 (4.5228)\tPrec@1 0.781 (0.781)\n",
            "Epoch: [1][100/196]\tTime 0.133 (0.150)\tData 0.000 (0.010)\tLoss 4.4779 (4.5050)\tPrec@1 1.562 (2.150)\n",
            "Test: [0/79]\tTime 0.630 (0.630)\tLoss 4.9961 (4.9961)\tPrec@1 0.000 (0.000)\n",
            " * Prec@1 0.450\n",
            "current lr 1.00000e-01\n",
            "Epoch: [2][0/196]\tTime 1.250 (1.250)\tData 0.868 (0.868)\tLoss 4.2578 (4.2578)\tPrec@1 4.688 (4.688)\n",
            "Epoch: [2][100/196]\tTime 0.131 (0.151)\tData 0.000 (0.009)\tLoss 4.0926 (4.1882)\tPrec@1 5.859 (4.726)\n",
            "Test: [0/79]\tTime 0.536 (0.536)\tLoss 5.6583 (5.6583)\tPrec@1 1.562 (1.562)\n",
            " * Prec@1 0.730\n",
            "current lr 1.00000e-01\n",
            "Epoch: [3][0/196]\tTime 1.230 (1.230)\tData 0.873 (0.873)\tLoss 3.8977 (3.8977)\tPrec@1 7.422 (7.422)\n",
            "Epoch: [3][100/196]\tTime 0.135 (0.150)\tData 0.000 (0.009)\tLoss 3.8151 (3.8348)\tPrec@1 12.891 (9.278)\n",
            "Test: [0/79]\tTime 0.601 (0.601)\tLoss 5.2809 (5.2809)\tPrec@1 0.000 (0.000)\n",
            " * Prec@1 0.290\n",
            "current lr 1.00000e-01\n",
            "Epoch: [4][0/196]\tTime 1.301 (1.301)\tData 0.930 (0.930)\tLoss 3.5015 (3.5015)\tPrec@1 14.453 (14.453)\n",
            "Epoch: [4][100/196]\tTime 0.135 (0.150)\tData 0.000 (0.009)\tLoss 3.4943 (3.5087)\tPrec@1 12.891 (15.180)\n",
            "Test: [0/79]\tTime 0.515 (0.515)\tLoss 5.8418 (5.8418)\tPrec@1 0.000 (0.000)\n",
            " * Prec@1 2.200\n",
            "current lr 1.00000e-01\n",
            "Epoch: [5][0/196]\tTime 1.404 (1.404)\tData 1.004 (1.004)\tLoss 3.1770 (3.1770)\tPrec@1 21.094 (21.094)\n",
            "Epoch: [5][100/196]\tTime 0.133 (0.150)\tData 0.000 (0.010)\tLoss 2.9987 (3.1838)\tPrec@1 28.516 (21.047)\n",
            "Test: [0/79]\tTime 0.687 (0.687)\tLoss 6.7398 (6.7398)\tPrec@1 0.000 (0.000)\n",
            " * Prec@1 0.350\n",
            "current lr 1.00000e-01\n",
            "Epoch: [6][0/196]\tTime 1.331 (1.331)\tData 0.982 (0.982)\tLoss 3.1307 (3.1307)\tPrec@1 23.438 (23.438)\n",
            "Epoch: [6][100/196]\tTime 0.134 (0.150)\tData 0.000 (0.010)\tLoss 2.7736 (2.9421)\tPrec@1 31.250 (26.040)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RbDHHylJMp3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}